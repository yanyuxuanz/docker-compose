input {
  file{
      path => "/var/log/*.log"
      start_position => "beginning"
      codec => multiline {
        # 以"# Time:"为分隔符，中间的所有多行内容归为一行并填充到Event时间中
        pattern => "^# Time:"
        negate => true
        what => "previous"
        # 指定最多读取多少行，默认500行（以防执行初始数据库数据sql语句超过默认行）
        max_lines => 20000
      }
  }
}


filter {
  grok {
    # 在使用codec/multiline搭配使用的时候，需要注意，grok和普通正则一样默认是不支持匹配回车换行的。就像你需要=～//m一样也需要单独指定，具体写法是在表达式开始位置加(?m)标记
    match => { "message" => "(?m)^# Time:.*\s+#\s+User@Host:\s+%{USER:user}\[[^\]]+\]\s+@\s+(?:(?<clientip>\S*) )?\[(?:%{IPV4:clientip})?\]\s+Id:\s+%{NUMBER:row_id:int}\n#\s+Query_time:\s+%{NUMBER:query_time:float}\s+Lock_time:\s+%{NUMBER:lock_time:float}\s+Rows_sent:\s+%{NUMBER:rows_sent:int}\s+Rows_examined:\s+%{NUMBER:rows_examined:int}\n\s*(?:use %{DATA:database};\s*\n)?SET\s+timestamp=%{NUMBER:timestamp};\n\s*(?<sql>(?<action>\w+)\b.*)$" }

    # 对于能匹配上面Grok正则的message就删除掉，不能匹配会原始保留
    remove_field => [ "message" ] 
  }

  #mutate {
  #  gsub => [ "sql", "\n# Time: \d+\s+\d+:\d+:\d+", "" ]
  #}

  date {
    match => [ "timestamp", "UNIX" ]
    remove_field => [ "timestamp" ]
  }
}

output {
  elasticsearch { 
    hosts => ["elasticsearch:9200"] 
    index=>"ws-prod-log-%{+YYYY.MM.dd}"
    document_type => "_doc"
    http_compression => true
    user     => "elastic"
    password => "feb1f9a47775a60b57e87cfc5ba1924d"
  }
}